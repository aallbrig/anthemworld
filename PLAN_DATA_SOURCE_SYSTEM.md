# Plan: Sophisticated Data Source Management System

## âœ… COMPLETED: mkdir -p for data format

**Implementation:**
- Updated `cli/worldanthem/cmd/data.go` to use `os.MkdirAll()`
- Added directory creation with 0755 permissions
- Added write permission test
- Tested successfully: `./bin/worldanthem data format --output ./tmp/test/nested` âœ…

**Result:** Users can now specify any nested output path, and all directories will be created automatically.

```bash
# These all work now:
worldanthem data format --output ./tmp
worldanthem data format --output ./hugo/site/static/data
worldanthem data format --output /any/absolute/path
```

---

## ðŸŽ¯ Goal: Dynamic Data Source Management

Create a sophisticated system where:
1. **Data sources registered in database** with schemas and health endpoints
2. **Health checks** via `data sources status` command
3. **Downloads** via `data download` command (including GeoJSON)
4. **Status roll-up**: `data sources` â†’ `data status` â†’ `status`
5. **Job tracking** in database with detailed logs
6. **JSON export** for frontend consumption

### Architecture

```
Commands:
  status
    â”œâ”€> data status
    â”‚     â”œâ”€> Database info & counts
    â”‚     â””â”€> data sources status
    â”‚           â””â”€> Health check all sources
    â””â”€> jobs status
          â””â”€> Active & completed jobs

  data download
    â””â”€> Orchestrator
          â”œâ”€> Health check
          â”œâ”€> Create job
          â”œâ”€> Worker pool (rate-limited)
          â”œâ”€> Download from sources
          â””â”€> Update database

  data format --output <dir>
    â””â”€> Export JSON files
          â”œâ”€> anthems.json
          â”œâ”€> audio.json
          â”œâ”€> countries-metadata.json
          â”œâ”€> countries.geojson
          â””â”€> index.json
```

### Data Sources (5 initial)

1. **REST Countries API** â†’ countries table
2. **Wikidata SPARQL** â†’ anthems table
3. **Wikimedia Commons** â†’ audio_recordings table
4. **GeoJSON Boundaries** â†’ countries.geojson_geometry column
5. **World Countries JSON** â†’ countries native names enrichment

---

## Database Schema Changes

### New Tables

**data_source_schemas** - Field mappings per source
```sql
CREATE TABLE IF NOT EXISTS data_source_schemas (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    source_id TEXT NOT NULL,
    target_table TEXT NOT NULL,
    field_mappings TEXT NOT NULL,  -- JSON
    transform_rules TEXT,          -- JSON (optional)
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (source_id) REFERENCES data_sources(id)
);
```

**job_logs** - Detailed logging
```sql
CREATE TABLE IF NOT EXISTS job_logs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    job_id TEXT NOT NULL,
    level TEXT NOT NULL,           -- INFO, WARN, ERROR
    message TEXT NOT NULL,
    source_id TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (job_id) REFERENCES jobs(id)
);
```

### Schema Updates

**data_sources** - Enhanced
```sql
ALTER TABLE data_sources ADD COLUMN rate_limit_per_second INTEGER DEFAULT 10;
ALTER TABLE data_sources ADD COLUMN requires_auth BOOLEAN DEFAULT 0;
ALTER TABLE data_sources ADD COLUMN health_check_endpoint TEXT;
ALTER TABLE data_sources ADD COLUMN download_strategy TEXT DEFAULT 'api';
```

**countries** - Add geometry
```sql
ALTER TABLE countries ADD COLUMN geojson_geometry TEXT;
```

---

## Implementation Phases

### Phase 1: Foundation (4-6 hours)

**Create:**
- [ ] Database migration file `002_data_sources.sql`
- [ ] `pkg/sources/` package
- [ ] `DataSource` interface
- [ ] `Registry` struct
- [ ] 5 initial data source definitions

**Interface:**
```go
type DataSource interface {
    ID() string
    Name() string
    Type() string
    URL() string
    HealthCheck(ctx context.Context) error
    Download(ctx context.Context, job *Job) error
    GetSchema() SchemaMapping
    GetRateLimit() int
}
```

**Command:**
```bash
$ worldanthem data sources

Registered Data Sources
=======================
1. rest-countries          REST Countries API
2. wikidata-sparql         Wikidata Query Service
3. wikimedia-commons       Wikimedia Commons API
4. geo-countries-geojson   GeoJSON Boundaries
5. world-countries-json    World Countries JSON
```

### Phase 2: Health Checks (2-3 hours)

**Create:**
- [ ] `pkg/sources/health.go`
- [ ] HTTP client with timeouts
- [ ] Health check per source type
- [ ] Store results in database
- [ ] `data sources status` command
- [ ] Update `data status` to call it

**Output:**
```bash
$ worldanthem data sources status

Data Sources Health
===================
âœ“ REST Countries API         HEALTHY (142ms)
âœ“ Wikidata SPARQL           HEALTHY (256ms)
âœ“ Wikimedia Commons         HEALTHY (98ms)
âœ“ GeoJSON Countries         HEALTHY (312ms)
âœ— World Countries JSON      DOWN (timeout)

Overall: 4/5 sources healthy
Last checked: 2026-02-14 18:00:00 UTC
```

### Phase 3: Download Infrastructure (6-8 hours)

**Create:**
- [ ] `pkg/download/` package
- [ ] Worker pool pattern
- [ ] Rate limiter per source
- [ ] Job creation & tracking
- [ ] Job logs to database
- [ ] Download orchestrator
- [ ] `data download` command

**Usage:**
```bash
# Download all
worldanthem data download

# Download specific sources
worldanthem data download --sources rest-countries,geojson

# Dry run
worldanthem data download --dry-run
```

**Output:**
```bash
$ worldanthem data download

Starting download from 5 sources...

âœ“ Health check passed (4/5 sources healthy)

Creating job [job_abc123]...

[1/4] rest-countries: Downloading countries...
      Progress: 193/193 (100%) âœ“ Complete

[2/4] geo-countries-geojson: Downloading boundaries...
      Progress: 100% âœ“ Complete
      Stored 193 geometries

Job completed in 3m 42s
Records: 542
```

### Phase 4: GeoJSON Integration (3-4 hours)

**Create:**
- [ ] `pkg/sources/geojson.go`
- [ ] Download to cache (`~/.cache/anthemworld/`)
- [ ] Parse GeoJSON features
- [ ] Extract ISO codes
- [ ] Store geometry in database
- [ ] Handle missing countries

**Logic:**
```go
func (g *GeoJSONSource) Download(ctx context.Context, job *Job) error {
    // 1. Download file
    resp, _ := http.Get(g.url)
    
    // 2. Cache locally
    cacheFile := filepath.Join(cacheDir, "countries.geojson")
    os.WriteFile(cacheFile, data, 0644)
    
    // 3. Parse
    var geojson GeoJSON
    json.Unmarshal(data, &geojson)
    
    // 4. Store in DB
    for _, feature := range geojson.Features {
        isoCode := feature.Properties["ISO_A3"]
        geometry, _ := json.Marshal(feature.Geometry)
        
        db.Exec(`
            UPDATE countries 
            SET geojson_geometry = ?
            WHERE iso_alpha3 = ?
        `, string(geometry), isoCode)
    }
    
    return nil
}
```

### Phase 5: Data Export (3-4 hours)

**Create:**
- [ ] `pkg/format/` package
- [ ] JSON export per table
- [ ] Generate `index.json` manifest
- [ ] Export GeoJSON (reconstruct from DB)
- [ ] Update `data format` command

**Files Generated:**
```
hugo/site/static/data/
â”œâ”€â”€ index.json              # Manifest
â”œâ”€â”€ anthems.json           # Indexed by ISO code
â”œâ”€â”€ audio.json             # Indexed by audio ID
â”œâ”€â”€ countries-metadata.json
â””â”€â”€ countries.geojson      # Reconstructed
```

**anthems.json Example:**
```json
{
  "USA": {
    "country_code": "USA",
    "anthem_name": "The Star-Spangled Banner",
    "composer": "John Stafford Smith",
    "adopted_date": "1931-03-03",
    "audio_ids": ["usa_001", "usa_002"]
  }
}
```

### Phase 6: Job Management (4-5 hours)

**Create:**
- [ ] Job progress tracking
- [ ] Real-time updates
- [ ] `jobs logs <job_id>` command
- [ ] Enhanced `jobs status` output

**Output:**
```bash
$ worldanthem jobs status

--- Jobs Status ---
Status: RUNNING (1 active job)

Active Jobs:
  [Job abc123] data-download
    Progress: 145/193 (75%)
    Current: wikimedia-commons
    Started: 17:55:00 UTC
    Duration: 5m 23s
    
    Completed:
      âœ“ rest-countries (193 countries)
      âœ“ geo-countries-geojson (193 geometries)

$ worldanthem jobs logs abc123

[17:55:00] INFO  Starting download job
[17:55:01] INFO  Health check: 4/5 sources healthy
[17:55:02] INFO  rest-countries: Starting download
[17:55:27] INFO  rest-countries: Downloaded 193 countries
[17:55:28] INFO  geo-countries-geojson: Downloading file
[17:55:45] INFO  geo-countries-geojson: Parsed 193 features
...
```

---

## Package Structure

```
cli/worldanthem/
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ data.go          # âœ… Updated with mkdir -p
â”‚   â””â”€â”€ jobs.go          # Job commands
â”œâ”€â”€ pkg/
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ db.go       # Database layer
â”‚   â”‚   â””â”€â”€ migrations.go # NEW
â”‚   â”œâ”€â”€ sources/        # NEW PACKAGE
â”‚   â”‚   â”œâ”€â”€ registry.go
â”‚   â”‚   â”œâ”€â”€ source.go
â”‚   â”‚   â”œâ”€â”€ health.go
â”‚   â”‚   â”œâ”€â”€ rest_countries.go
â”‚   â”‚   â”œâ”€â”€ wikidata.go
â”‚   â”‚   â”œâ”€â”€ wikimedia.go
â”‚   â”‚   â””â”€â”€ geojson.go
â”‚   â”œâ”€â”€ download/       # NEW PACKAGE
â”‚   â”‚   â”œâ”€â”€ orchestrator.go
â”‚   â”‚   â”œâ”€â”€ worker.go
â”‚   â”‚   â””â”€â”€ ratelimit.go
â”‚   â””â”€â”€ format/         # NEW PACKAGE
â”‚       â”œâ”€â”€ json.go
â”‚       â””â”€â”€ export.go
```

---

## Workflow Examples

### Fresh Install
```bash
# 1. Check status
worldanthem status
# Shows: Database not created, no data

# 2. Check sources health
worldanthem data sources status
# Shows: 4/5 sources healthy

# 3. Download data
worldanthem data download
# Downloads from all healthy sources
# Creates job, tracks progress
# Stores in SQLite

# 4. Check status again
worldanthem status
# Shows: 193 countries, 187 anthems, 245 audio files

# 5. Export for frontend
worldanthem data format --output hugo/site/static/data
# Generates:
#   - anthems.json
#   - audio.json
#   - countries-metadata.json
#   - countries.geojson
#   - index.json

# 6. Run Hugo
hugo server -s hugo/site -D
# Map now has clickable boundaries with anthem data!
```

---

## Timeline

- **Phase 1**: 4-6 hours
- **Phase 2**: 2-3 hours  
- **Phase 3**: 6-8 hours
- **Phase 4**: 3-4 hours
- **Phase 5**: 3-4 hours
- **Phase 6**: 4-5 hours

**Total**: ~25-35 hours

---

## Benefits

âœ… **Status Roll-up**: Everything visible via `status` command  
âœ… **Health Monitoring**: Know which sources work  
âœ… **Job Tracking**: Full download visibility  
âœ… **Extensible**: Easy to add new sources  
âœ… **Robust**: Rate limiting, retries, errors handled  
âœ… **GeoJSON Integrated**: Boundaries in database  
âœ… **Frontend Ready**: JSON export for static site  
âœ… **Single Source**: Database is truth, files are export  

---

## Design Decisions

**Q: Store GeoJSON in database or file?**  
A: **Database** (as TEXT column). Export to file for frontend. Single source of truth.

**Q: How to handle data conflicts?**  
A: Add `source_priority` column. Higher priority overrides.

**Q: Support incremental updates?**  
A: Phase 2 feature. Full download for MVP.

**Q: Authentication?**  
A: Add `auth_type` and `auth_config` columns. Support env vars.

---

## Next Steps

1. Review and approve this plan
2. Start Phase 1 (Foundation)
3. Create database migrations
4. Implement data source registry
5. Build incrementally, test each phase

**Status**: âœ… Ready to implement
